"""
CallCops: Training Script
==============================

Real-Time Audio Watermarking ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸.

í•™ìŠµ ì „ëµ:
1. Generator (Encoder + Decoder) í•™ìŠµ: Bit Loss + Audio Loss + Adversarial Loss
2. Discriminator í•™ìŠµ: Real vs Fake íŒë³„
3. Codec Augmentation (Optional): G.711/G.729 robustness ê°•í™”

í’ˆì§ˆ ëª©í‘œ:
- PESQ >= 4.0
- BER < 5%

Usage:
    python scripts/train.py --epochs 100 --batch_size 64
    python scripts/train.py --config configs/default.yaml --resume checkpoints/latest.pth
"""

import os
import sys
import argparse
import traceback
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, Tuple

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.cuda.amp import GradScaler, autocast
import yaml
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from models import CallCopsNet, CallCopsLoss, DifferentiableCodecSimulator
from scripts.dataset import create_train_val_loaders, create_dataloader
from utils.messenger import CallCopsMessenger


# =============================================================================
# Utility Functions
# =============================================================================

def compute_snr(original: torch.Tensor, watermarked: torch.Tensor) -> float:
    """
    Signal-to-Noise Ratio ê³„ì‚°

    SNR = 10 * log10(mean(xÂ²) / mean((x-x')Â²))
    Note: sum ëŒ€ì‹  meanì„ ì‚¬ìš©í•˜ì—¬ ê¸´ ì˜¤ë””ì˜¤/í° ë°°ì¹˜ì—ì„œì˜ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€

    Args:
        original: [B, 1, T] ì›ë³¸ ì˜¤ë””ì˜¤
        watermarked: [B, 1, T] ì›Œí„°ë§ˆí¬ëœ ì˜¤ë””ì˜¤

    Returns:
        SNR in dB
    """
    signal_power = torch.mean(original ** 2)
    noise_power = torch.mean((original - watermarked) ** 2)

    if noise_power < 1e-10:
        return 100.0  # ê±°ì˜ ë™ì¼í•œ ê²½ìš°

    snr = 10 * torch.log10(signal_power / (noise_power + 1e-10))
    return snr.item()


def compute_ber(pred_logits: torch.Tensor, target_bits: torch.Tensor) -> float:
    """
    Bit Error Rate ê³„ì‚° (í”„ë ˆì„ ë‹¨ìœ„ í˜¸í™˜)

    Args:
        pred_logits: [B, num_frames] ì˜ˆì¸¡ëœ ë¡œì§“ (í”„ë ˆì„ë³„)
        target_bits: [B, 128] ë˜ëŠ” [B, num_frames] ëª©í‘œ ë¹„íŠ¸

    Returns:
        BER (0~1)
    """
    B, num_frames = pred_logits.shape
    
    # target_bitsë¥¼ í”„ë ˆì„ ìˆ˜ì— ë§ê²Œ í™•ì¥ (Cyclic)
    if target_bits.shape[1] != num_frames:
        # target_bits: [B, 128] -> [B, num_frames]
        frame_indices = torch.arange(num_frames, device=target_bits.device) % target_bits.shape[1]
        target_bits_expanded = target_bits[:, frame_indices]
    else:
        target_bits_expanded = target_bits
    
    pred_bits = (torch.sigmoid(pred_logits) > 0.5).float()
    errors = (pred_bits != target_bits_expanded).float()
    return errors.mean().item()


def get_frame_target_bits(bits: torch.Tensor, num_frames: int) -> torch.Tensor:
    """
    128ë¹„íŠ¸ í˜ì´ë¡œë“œë¥¼ í”„ë ˆì„ ìˆ˜ì— ë§ê²Œ Cyclic í™•ì¥
    
    Args:
        bits: [B, 128] ì›ë³¸ í˜ì´ë¡œë“œ
        num_frames: íƒ€ê²Ÿ í”„ë ˆì„ ìˆ˜
        
    Returns:
        frame_bits: [B, num_frames] í”„ë ˆì„ë³„ ë¹„íŠ¸
    """
    frame_indices = torch.arange(num_frames, device=bits.device) % bits.shape[1]
    return bits[:, frame_indices]


# =============================================================================
# Trainer Class
# =============================================================================

class CallCopsTrainer:
    """
    CallCops ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ
    ======================

    GAN ê¸°ë°˜ í•™ìŠµ ë£¨í”„:
    1. Discriminator Update: Real vs Fake íŒë³„
    2. Generator Update: Bit Loss + Audio Loss + Adversarial Loss
    """

    def __init__(
        self,
        model: CallCopsNet,
        loss_fn: CallCopsLoss,
        opt_g: optim.Optimizer,
        opt_d: optim.Optimizer,
        device: torch.device,
        codec_sim: Optional[DifferentiableCodecSimulator] = None,
        grad_clip: float = 1.0,
        use_amp: bool = False,
        messenger: Optional[CallCopsMessenger] = None
    ):
        self.model = model
        self.loss_fn = loss_fn
        self.opt_g = opt_g
        self.opt_d = opt_d
        self.device = device
        self.codec_sim = codec_sim
        self.grad_clip = grad_clip
        self.use_amp = use_amp
        self.messenger = messenger

        # Mixed precision scaler
        self.scaler = GradScaler() if use_amp else None

        # í•™ìŠµ ìƒíƒœ
        self.current_epoch = 0
        self.global_step = 0
        self.best_ber = 1.0
        self.best_loss = float('inf')
        
        # í•™ìŠµ ì´ë ¥ (PlotíŒ…ìš©)
        self.history = {
            'train_loss': [], 'val_loss': [],
            'train_ber': [], 'val_ber': []
        }

    def train_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """
        ë‹¨ì¼ í•™ìŠµ ìŠ¤í… (GAN Training with AMP)

        1. Discriminator Update: Maximize log(D(real)) + log(1 - D(fake))
        2. Generator Update: Minimize total loss (bit + audio + adv)
        """
        audio = batch['audio'].to(self.device)
        bits = batch['bits'].to(self.device)

        # ========================================
        # 1. Discriminator Update
        # ========================================
        self.opt_d.zero_grad()

        with torch.cuda.amp.autocast(enabled=self.use_amp, dtype=torch.bfloat16):
            with torch.no_grad():
                # Generator forward (no grad for D update)
                watermarked, _ = self.model.embed(audio, bits)

            # Discriminator forward
            disc_real = self.model.discriminator(audio)
            disc_fake = self.model.discriminator(watermarked.detach())

            # Discriminator loss
            d_loss = self.loss_fn.adv_loss.discriminator_loss(disc_real, disc_fake)

        # Backward & Step
        if self.use_amp:
            self.scaler.scale(d_loss).backward()
            self.scaler.unscale_(self.opt_d)
            torch.nn.utils.clip_grad_norm_(
                self.model.discriminator.parameters(),
                self.grad_clip
            )
            self.scaler.step(self.opt_d)
            # scaler.update()ëŠ” Generatorê¹Œì§€ ë‹¤ ëë‚œ í›„ í•œ ë²ˆë§Œ í˜¸ì¶œ
        else:
            d_loss.backward()
            torch.nn.utils.clip_grad_norm_(
                self.model.discriminator.parameters(),
                self.grad_clip
            )
            self.opt_d.step()

        # ========================================
        # 2. Generator Update
        # ========================================
        self.opt_g.zero_grad()

        with torch.cuda.amp.autocast(enabled=self.use_amp, dtype=torch.bfloat16):
            # Generator forward
            watermarked, _ = self.model.embed(audio, bits)

            # Codec simulation (optional, for robustness)
            if self.codec_sim is not None:
                watermarked_degraded, codec_used = self.codec_sim(watermarked)
            else:
                watermarked_degraded = watermarked
                codec_used = 'none'

            # Decoder forward (returns frame-wise logits)
            pred_logits = self.model.decoder(watermarked_degraded)  # [B, num_frames]

            # í”„ë ˆì„ ìˆ˜ì— ë§ê²Œ íƒ€ê²Ÿ ë¹„íŠ¸ í™•ì¥ (Cyclic)
            num_frames = pred_logits.shape[1]
            target_bits_expanded = get_frame_target_bits(bits, num_frames)

            # Detection logits: ë¹„íŠ¸ ë¡œì§“ì˜ ì ˆëŒ€ê°’ í‰ê· 
            detection_logits = torch.abs(pred_logits).mean(dim=1, keepdim=True)

            # Discriminator forward (for generator loss)
            disc_fake = self.model.discriminator(watermarked)

            # Generator losses (í”„ë ˆì„ ë‹¨ìœ„ ë¹„íŠ¸ ë¹„êµ)
            losses = self.loss_fn(
                pred_audio=watermarked,
                target_audio=audio,
                pred_bits=pred_logits,  # [B, num_frames] logits
                target_bits=target_bits_expanded,  # [B, num_frames] expanded
                detection_pred=detection_logits,
                disc_fake=disc_fake
            )
            
            g_loss = losses['total']

        # Backward & Step
        if self.use_amp:
            self.scaler.scale(g_loss).backward()
            self.scaler.unscale_(self.opt_g)
            torch.nn.utils.clip_grad_norm_(
                list(self.model.encoder.parameters()) +
                list(self.model.decoder.parameters()),
                self.grad_clip
            )
            self.scaler.step(self.opt_g)
            
            # Update scaler once per iteration
            self.scaler.update()
        else:
            g_loss.backward()
            torch.nn.utils.clip_grad_norm_(
                list(self.model.encoder.parameters()) +
                list(self.model.decoder.parameters()),
                self.grad_clip
            )
            self.opt_g.step()

        # ========================================
        # 3. Metrics
        # ========================================
        with torch.no_grad():
            # CPUë¡œ ì´ë™í•˜ì—¬ ê³„ì‚° (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
            ber = compute_ber(pred_logits.detach().float(), bits.detach().float())
            snr = compute_snr(audio.detach().float(), watermarked.detach().float())

        self.global_step += 1

        return {
            'loss_total': losses['total'].item(),
            'loss_bit': losses['bit'].item(),
            'loss_mel': losses['mel'].item(),
            'loss_stft': losses['stft'].item(),
            'loss_adv_g': losses['adv_g'].item(),
            'loss_adv_d': d_loss.item(),
            'ber': ber,
            'snr': snr,
            'codec': codec_used
        }

    @torch.no_grad()
    def validate(self, val_loader: DataLoader) -> Dict[str, float]:
        """ê²€ì¦ ë£¨í”„"""
        self.model.eval()

        total_metrics = {
            'loss': 0.0,
            'ber': 0.0,
            'snr': 0.0,
            'accuracy': 0.0
        }
        num_batches = 0

        for batch in val_loader:
            audio = batch['audio'].to(self.device)
            bits = batch['bits'].to(self.device)

            # Forward
            watermarked, _ = self.model.embed(audio, bits)
            pred_logits = self.model.decoder(watermarked)  # [B, num_frames]
            
            # í”„ë ˆì„ ìˆ˜ì— ë§ê²Œ íƒ€ê²Ÿ ë¹„íŠ¸ í™•ì¥ (Cyclic)
            num_frames = pred_logits.shape[1]
            target_bits_expanded = get_frame_target_bits(bits, num_frames)
            
            detection_logits = torch.abs(pred_logits).mean(dim=1, keepdim=True)

            # Losses (í”„ë ˆì„ ë‹¨ìœ„ ë¹„êµ)
            losses = self.loss_fn(
                pred_audio=watermarked,
                target_audio=audio,
                pred_bits=pred_logits,
                target_bits=target_bits_expanded,
                detection_pred=detection_logits
            )

            # Metrics
            ber = compute_ber(pred_logits, bits)
            snr = compute_snr(audio, watermarked)

            total_metrics['loss'] += losses['total'].item()
            total_metrics['ber'] += ber
            total_metrics['snr'] += snr
            total_metrics['accuracy'] += (1.0 - ber)

            num_batches += 1

        # Average
        for key in total_metrics:
            total_metrics[key] /= max(num_batches, 1)

        self.model.train()
        return total_metrics

    def train_epoch(
        self,
        train_loader: DataLoader,
        epoch: int,
        total_epochs: int
    ) -> Dict[str, float]:
        """ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        self.current_epoch = epoch

        # Codec curriculum (optional)
        if self.codec_sim is not None:
            self.codec_sim.set_epoch(epoch)

        epoch_metrics = {
            'loss_total': 0.0,
            'loss_bit': 0.0,
            'ber': 0.0,
            'snr': 0.0
        }

        pbar = tqdm(
            train_loader,
            desc=f"Epoch {epoch+1}/{total_epochs}",
            leave=True
        )

        for batch_idx, batch in enumerate(pbar):
            metrics = self.train_step(batch)

            # ëˆ„ì 
            for key in epoch_metrics:
                if key in metrics:
                    epoch_metrics[key] += metrics[key]

            # Progress bar
            pbar.set_postfix({
                'loss': f"{metrics['loss_total']:.4f}",
                'ber': f"{metrics['ber']:.4f}",
                'snr': f"{metrics['snr']:.1f}dB"
            })

        # Average
        num_batches = len(train_loader)
        for key in epoch_metrics:
            epoch_metrics[key] /= max(num_batches, 1)

        return epoch_metrics

    def save_checkpoint(
        self,
        path: Path,
        metrics: Dict[str, float],
        config: Optional[Dict] = None,
        is_latest: bool = False
    ):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': self.current_epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'opt_g_state_dict': self.opt_g.state_dict(),
            'opt_d_state_dict': self.opt_d.state_dict(),
            'best_ber': self.best_ber,
            'best_loss': self.best_loss,
            'metrics': metrics,
            'history': self.history
        }

        if config is not None:
            checkpoint['config'] = config

        path.parent.mkdir(parents=True, exist_ok=True)
        torch.save(checkpoint, path)
        print(f"Saved checkpoint to {path}")
        
        # Save latest link (or copy)
        if is_latest:
            latest_path = path.parent / "latest.pth"
            try:
                # ë®ì–´ì“°ê¸° ìœ„í•´ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
                if latest_path.exists():
                    latest_path.unlink()
                # ë³µì‚¬ê°€ ë” ì•ˆì •ì ì¼ ìˆ˜ ìˆìŒ (íŠ¹íˆ íŒŒì¼ì‹œìŠ¤í…œì— ë”°ë¼)
                shutil.copy(path, latest_path)
            except Exception as e:
                print(f"Warning: Failed to create latest.pth: {e}")

    def load_checkpoint(self, path: Path, new_lr: float = None):
        """
        ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        
        Args:
            path: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            new_lr: ìƒˆ Learning Rate (Noneì´ë©´ ì €ì¥ëœ LR ìœ ì§€, ê°’ ìˆìœ¼ë©´ ê°•ì œ ì ìš©)
        """
        print(f"Loading checkpoint from {path}...")
        checkpoint = torch.load(path, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.opt_g.load_state_dict(checkpoint['opt_g_state_dict'])
        self.opt_d.load_state_dict(checkpoint['opt_d_state_dict'])
        
        # LR ê°•ì œ ì¬ì„¤ì • (Fine-tuning ì‹œ í•„ìˆ˜!)
        if new_lr is not None:
            old_lr = self.opt_g.param_groups[0]['lr']
            for param_group in self.opt_g.param_groups:
                param_group['lr'] = new_lr
            for param_group in self.opt_d.param_groups:
                param_group['lr'] = new_lr
            print(f"âš ï¸ LR Override: {old_lr:.2e} â†’ {new_lr:.2e}")
        else:
            print(f"ğŸ“Š Keeping checkpoint LR: {self.opt_g.param_groups[0]['lr']:.2e}")
        
        self.current_epoch = checkpoint['epoch'] + 1
        self.global_step = checkpoint['global_step']
        self.best_ber = checkpoint.get('best_ber', 1.0)
        self.best_loss = checkpoint.get('best_loss', float('inf'))
        self.history = checkpoint.get('history', self.history)

        print(f"Loaded checkpoint from epoch {checkpoint['epoch']+1}")
        print(f"Best BER: {self.best_ber:.4f}")

        return checkpoint.get('config')


# =============================================================================
# Main Training Function
# =============================================================================

def train(
    train_loader: DataLoader,
    val_loader: DataLoader,
    config: Dict[str, Any],
    save_dir: Path,
    device: torch.device,
    resume_path: Optional[Path] = None
):
    """
    ë©”ì¸ í•™ìŠµ í•¨ìˆ˜
    """
    # 0. ë©”ì‹ ì € ì´ˆê¸°í™”
    messenger = CallCopsMessenger()
    messenger.send_message(f"ğŸš€ **CallCops Training Started**\nDevice: {device}\nSave Dir: `{save_dir}`")

    try:
        # ========================================
        # 1. Model ì´ˆê¸°í™”
        # ========================================
        training_config = config.get('training', {})
        model_config = config.get('model', {})

        model = CallCopsNet(
            message_dim=config.get('watermark', {}).get('payload_length', 128),
            hidden_channels=model_config.get('hidden_channels', [32, 64, 128, 256]),
            num_residual_blocks=model_config.get('num_residual_blocks', 4),
            use_discriminator=True
        ).to(device)

        # ========================================
        # 1.5 Encoder Alpha Override (Configì—ì„œ ê°•ì œ ì ìš©)
        # ========================================
        encoder_alpha = training_config.get('encoder_alpha', None)
        if encoder_alpha is not None:
            old_alpha = model.encoder.alpha.item()
            model.encoder.alpha.fill_(encoder_alpha)
            model.encoder.alpha_min = encoder_alpha
            print(f"âš ï¸ Encoder Alpha Override: {old_alpha:.3f} â†’ {encoder_alpha:.3f}")

        # íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥
        params = model.count_parameters()
        print(f"\nModel Parameters:")
        print(f"  Encoder: {params['encoder']:,}")
        print(f"  Decoder: {params['decoder']:,}")
        print(f"  Discriminator: {params['discriminator']:,}")
        print(f"  Total: {params['total']:,}")

        # ========================================
        # 2. Loss Function
        # ========================================
        loss_fn = CallCopsLoss(
            lambda_bit=training_config.get('lambda_bit', 10.0),
            lambda_audio=training_config.get('lambda_audio', 10.0),
            lambda_adv=training_config.get('lambda_adv', 0.1),
            lambda_det=training_config.get('lambda_det', 0.5),
            lambda_stft=training_config.get('lambda_stft', 2.0),
            lambda_l1=training_config.get('lambda_l1', 10.0),  # NEW: Direct L1 loss for SNR
            sample_rate=config.get('audio', {}).get('sample_rate', 8000)
        ).to(device)

        # ========================================
        # 3. Optimizers (LR: 2e-4)
        # ========================================
        lr = training_config.get('learning_rate', 2e-4)
        betas = tuple(training_config.get('adam_betas', [0.5, 0.9]))

        opt_g = optim.Adam(
            list(model.encoder.parameters()) + list(model.decoder.parameters()),
            lr=lr,
            betas=betas
        )

        opt_d = optim.Adam(
            model.discriminator.parameters(),
            lr=lr,
            betas=betas
        )

        # ========================================
        # 3.5 LR Scheduler (ReduceLROnPlateau)
        # ========================================
        # ì„ íƒ ì´ìœ : ì´ í•™ìŠµì—ì„œëŠ” Val Loss ë³€ë™í­ì´ ë§¤ìš° í¼ (32~76)
        # - CosineAnnealing: ê³ ì •ëœ ìŠ¤ì¼€ì¤„ì´ë¯€ë¡œ ê°‘ì‘ìŠ¤ëŸ° spikeì— ëŒ€ì‘ ë¶ˆê°€
        # - ReduceLROnPlateau: ì‹¤ì œ ì„±ëŠ¥ ê¸°ë°˜ìœ¼ë¡œ LR ì¡°ì •, ë¶ˆì•ˆì •í•œ í•™ìŠµì— ì í•©
        scheduler_g = optim.lr_scheduler.ReduceLROnPlateau(
            opt_g,
            mode='min',          # val_lossë¥¼ ìµœì†Œí™”
            factor=0.5,          # LRì„ ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ
            patience=3,          # 3 ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ë°œë™
            min_lr=1e-7          # ìµœì†Œ LR í•˜í•œ
        )
        scheduler_d = optim.lr_scheduler.ReduceLROnPlateau(
            opt_d,
            mode='min',
            factor=0.5,
            patience=3,
            min_lr=1e-7
        )

        # ========================================
        # 4. Codec Simulator (Optional)
        # ========================================
        codec_sim = None
        codec_config = config.get('codec', {})
        if codec_config.get('enabled', False):
            codec_sim = DifferentiableCodecSimulator(
                codec_types=codec_config.get('types', ['g711_alaw', 'g729', 'none']),
                curriculum_epochs=training_config.get('curriculum_epochs', 10)
            ).to(device)

        # ========================================
        # 5. Trainer
        # ========================================
        trainer = CallCopsTrainer(
            model=model,
            loss_fn=loss_fn,
            opt_g=opt_g,
            opt_d=opt_d,
            device=device,
            codec_sim=codec_sim,
            grad_clip=training_config.get('grad_clip', 1.0),
            use_amp=training_config.get('use_amp', True),  # AMP Enabled by default
            messenger=messenger
        )

        # ì²´í¬í¬ì¸íŠ¸ ë³µì› (LRì€ config ê°’ìœ¼ë¡œ ê°•ì œ ì¬ì„¤ì •!)
        if resume_path and resume_path.exists():
            trainer.load_checkpoint(resume_path, new_lr=lr)  # ì¤‘ìš”: config LR ê°•ì œ ì ìš©
            messenger.send_message(f"ğŸ”„ **Resumed Training** from epoch {trainer.current_epoch}\nğŸ“Š LR Override: `{lr:.2e}`")

            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ í›„ Alpha ì¬ê°•ì œ (ì²´í¬í¬ì¸íŠ¸ê°€ ì´ì „ alphaë¥¼ ë³µì›í•  ìˆ˜ ìˆìŒ)
            if encoder_alpha is not None:
                model.encoder.alpha.fill_(encoder_alpha)
                model.encoder.alpha_min = encoder_alpha
                print(f"âš ï¸ Post-Checkpoint Alpha Re-enforced: {encoder_alpha:.3f}")

        # ========================================
        # 6. Training Loop
        # ========================================
        num_epochs = training_config.get('epochs', 100)
        save_dir.mkdir(parents=True, exist_ok=True)

        # ========================================
        # Early Stopping Setup (SNR ê¸°ë°˜)
        # ========================================
        es_config = training_config.get('early_stopping', {})
        es_enabled = es_config.get('enabled', False)
        es_min_snr = es_config.get('min_snr', 15.0)
        es_patience = es_config.get('patience', 10)
        es_counter = 0  # ì—°ì†ìœ¼ë¡œ SNR < min_snrì¸ ì—í¬í¬ ìˆ˜
        best_val_snr = 0.0

        if es_enabled:
            print(f"\nâš¡ Early Stopping ENABLED: monitor=val_snr, min_snr={es_min_snr}dB, patience={es_patience}")

        print("\n" + "=" * 60)
        print("CallCops Training Started")
        print("=" * 60)
        print(f"  Device: {device}")
        print(f"  Epochs: {num_epochs}")
        print(f"  Batch size: {config.get('training', {}).get('batch_size', 64)}")
        print(f"  Learning rate: {lr}")
        print(f"  Training samples: {len(train_loader.dataset)}")
        print(f"  Validation samples: {len(val_loader.dataset)}")
        print(f"  Codec simulation: {'Enabled' if codec_sim else 'Disabled'}")
        print("=" * 60 + "\n")

        for epoch in range(trainer.current_epoch, num_epochs):
            # Train
            train_metrics = trainer.train_epoch(train_loader, epoch, num_epochs)

            # Validate
            val_metrics = trainer.validate(val_loader)

            # Update History
            trainer.history['train_loss'].append(train_metrics['loss_total'])
            trainer.history['val_loss'].append(val_metrics['loss'])
            trainer.history['train_ber'].append(train_metrics['ber'])
            trainer.history['val_ber'].append(val_metrics['ber'])

            # LR Scheduler Step (ReduceLROnPlateau: val_loss ê¸°ë°˜)
            scheduler_g.step(val_metrics['loss'])
            scheduler_d.step(val_metrics['loss'])
            current_lr = opt_g.param_groups[0]['lr']

            # ========================================
            # Dynamic Weight Controller (ë¡œì»¬ ë¯¸ë‹ˆë§ˆ íƒˆì¶œ)
            # ========================================
            # BERì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ â†’ bit ì••ë°• ì™„í™”, audioì— ì§‘ì¤‘
            if val_metrics['ber'] < 0.02:  # BER < 2%
                old_lambda_bit = loss_fn.lambda_bit
                loss_fn.lambda_bit = max(0.1, loss_fn.lambda_bit * 0.8)
                print(f"  ğŸ›ï¸ Dynamic: lambda_bit {old_lambda_bit:.2f} â†’ {loss_fn.lambda_bit:.2f} (BER over-optimized)")
            
            # SNRì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ â†’ audio ì••ë°• ê°•í™”
            if val_metrics['snr'] < 15.0:  # SNR < 15dB
                old_lambda_audio = loss_fn.lambda_audio
                loss_fn.lambda_audio = min(500.0, loss_fn.lambda_audio * 1.1)
                print(f"  ğŸ›ï¸ Dynamic: lambda_audio {old_lambda_audio:.1f} â†’ {loss_fn.lambda_audio:.1f} (SNR too low)")

            # ========================================
            # Early Stopping Check (SNR ê¸°ë°˜)
            # ========================================
            if es_enabled:
                current_snr = val_metrics['snr']

                if current_snr < es_min_snr:
                    es_counter += 1
                    print(f"  âš ï¸ Early Stop Warning: Val SNR={current_snr:.1f}dB < {es_min_snr}dB "
                          f"({es_counter}/{es_patience})")
                else:
                    if es_counter > 0:
                        print(f"  âœ… SNR recovered to {current_snr:.1f}dB, resetting early stop counter")
                    es_counter = 0

                if es_counter >= es_patience:
                    stop_msg = (
                        f"ğŸ›‘ **Early Stopping Triggered!**\n"
                        f"Val SNR < {es_min_snr}dB for {es_patience} consecutive epochs.\n"
                        f"Last SNR: {current_snr:.1f}dB | Best SNR: {best_val_snr:.1f}dB\n"
                        f"BER at stop: {val_metrics['ber']:.4f}"
                    )
                    print(f"\n{stop_msg}")
                    if messenger:
                        messenger.send_message(stop_msg)

                    # ì¢…ë£Œ ì „ ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                    trainer.save_checkpoint(
                        save_dir / f"early_stop_epoch{epoch+1}.pth",
                        val_metrics,
                        config
                    )
                    break

            # Summary
            summary_text = (
                f"âœ… **Epoch {epoch+1}/{num_epochs}**\n"
                f"ğŸ“‰ Train Loss: `{train_metrics['loss_total']:.4f}`\n"
                f"ğŸ“‰ Val Loss: `{val_metrics['loss']:.4f}`\n"
                f"ğŸ¯ **Val BER**: `{val_metrics['ber']:.4f}`\n"
                f"ğŸ”Š Val SNR: `{val_metrics['snr']:.1f}dB`\n"
                f"ğŸ“Š LR: `{current_lr:.2e}`"
            )
            
            print(f"\n{summary_text.replace('**', '').replace('`', '')}")

            # Send Notification
            if messenger:
                messenger.send_message(f"{summary_text}\n\n{messenger.get_system_info()}")

                # Send Plot every 10 epochs
                if (epoch + 1) % 10 == 0:
                    messenger.send_plot(trainer.history, title=f"Training Status (Epoch {epoch+1})")

            # Save Latest Checkpoint (ë§¤ ì—í¬í¬ë§ˆë‹¤)
            trainer.save_checkpoint(
                save_dir / f"checkpoint_epoch{epoch+1}.pth",
                val_metrics,
                config,
                is_latest=True
            )

            # 1. Best BER Model
            is_best_ber = val_metrics['ber'] < trainer.best_ber
            if is_best_ber:
                trainer.best_ber = val_metrics['ber']
                trainer.save_checkpoint(
                    save_dir / "best_ber_model.pth",
                    val_metrics,
                    config
                )
                print(f"  â˜… New best BER model! BER: {trainer.best_ber:.4f}")
                if messenger:
                    messenger.send_message(f"ğŸ† **New Best BER!** `{trainer.best_ber:.4f}`")

            # 2. Best Loss Model
            is_best_loss = val_metrics['loss'] < trainer.best_loss
            if is_best_loss:
                trainer.best_loss = val_metrics['loss']
                trainer.save_checkpoint(
                    save_dir / "best_loss_model.pth",
                    val_metrics,
                    config
                )
                print(f"  â˜… New best Loss model! Loss: {trainer.best_loss:.4f}")

            # 3. Best SNR Model (SNR Rescue ì‹œ ê°€ì¥ ì¤‘ìš”í•œ ì§€í‘œ)
            if val_metrics['snr'] > best_val_snr:
                best_val_snr = val_metrics['snr']
                trainer.save_checkpoint(
                    save_dir / "best_snr_model.pth",
                    val_metrics,
                    config
                )
                print(f"  â˜… New best SNR model! SNR: {best_val_snr:.1f}dB (BER: {val_metrics['ber']:.4f})")
                if messenger:
                    messenger.send_message(f"ğŸ“¡ **New Best SNR!** `{best_val_snr:.1f}dB` (BER: `{val_metrics['ber']:.4f}`)")

            # ì£¼ê¸°ì  ì˜êµ¬ ì €ì¥ (10 ì—í¬í¬ë§ˆë‹¤ ë³„ë„ íŒŒì¼ë¡œ ë‚¨ê¹€)
            if (epoch + 1) % 10 == 0:
                print(f"  Creating permanent checkpoint for epoch {epoch+1}...")
                # save_checkpointì—ì„œ ì´ë¯¸ ì €ì¥í–ˆìœ¼ë¯€ë¡œ ë³„ë„ ì‘ì—… ë¶ˆí•„ìš”

            print()

        # ìµœì¢… ì €ì¥
        trainer.save_checkpoint(
            save_dir / "final_model.pth",
            val_metrics,
            config
        )

        print("=" * 60)
        print("Training Completed!")
        print(f"Best BER: {trainer.best_ber:.4f}")
        print(f"Checkpoints saved to: {save_dir}")
        print("=" * 60)
        
        if messenger:
            messenger.send_message(f"ğŸ‰ **Training Completed**\nBest BER: `{trainer.best_ber:.4f}`")

    except Exception as e:
        error_msg = f"âŒ **Training Crashed!**\n\n```\n{traceback.format_exc()[-1000:]}\n```"
        print(traceback.format_exc())
        if messenger:
            messenger.send_message(error_msg)
        sys.exit(1)


# =============================================================================
# CLI Entry Point
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="CallCops Training Script",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # ë°ì´í„° ê²½ë¡œ
    parser.add_argument(
        '--train_dir', type=str, default='data/raw/training',
        help='Training data directory'
    )
    parser.add_argument(
        '--val_dir', type=str, default='data/raw/validation',
        help='Validation data directory'
    )

    # í•™ìŠµ ì„¤ì •
    parser.add_argument(
        '--epochs', type=int, default=100,
        help='Number of training epochs'
    )
    parser.add_argument(
        '--batch_size', type=int, default=64,
        help='Batch size (Default: 64 for RTX 3090)'
    )
    parser.add_argument(
        '--lr', type=float, default=2e-4,
        help='Learning rate'
    )

    # ëª¨ë¸ ì„¤ì •
    parser.add_argument(
        '--message_dim', type=int, default=128,
        help='Watermark message dimension (bits)'
    )

    # ê²½ë¡œ ì„¤ì •
    parser.add_argument(
        '--config', type=str, default=None,
        help='Path to config YAML file (overrides CLI args)'
    )
    parser.add_argument(
        '--save_dir', type=str, default='checkpoints',
        help='Directory to save checkpoints'
    )
    parser.add_argument(
        '--resume', type=str, default=None,
        help='Path to checkpoint to resume from'
    )

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    parser.add_argument(
        '--device', type=str, default='auto',
        choices=['auto', 'cuda', 'cpu'],
        help='Device to use'
    )
    parser.add_argument(
        '--num_workers', type=int, default=4,
        help='Number of data loading workers'
    )

    # ê¸°íƒ€
    parser.add_argument(
        '--seed', type=int, default=42,
        help='Random seed'
    )
    
    # ë””ë²„ê¹… ë° ì•ˆì •ì„±
    parser.add_argument(
        '--no_amp', action='store_true',
        help='Disable Mixed Precision (AMP) training (Recommended if loss=nan occurs)'
    )
    parser.add_argument(
        '--debug', action='store_true',
        help='Enable Anomaly Detection for debugging NaNs'
    )

    args = parser.parse_args()

    # ========================================
    # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
    # ========================================
    if args.debug:
        print("\nâš ï¸ DEBUG MODE ENABLED: Anomaly Detection is ON (This will slow down training)")
        torch.autograd.set_detect_anomaly(True)

    # ========================================
    # Config ë¡œë“œ ë˜ëŠ” ìƒì„±
    # ========================================
    if args.config and Path(args.config).exists():
        with open(args.config, 'r') as f:
            config = yaml.safe_load(f)
        print(f"Loaded config from: {args.config}")
    else:
        # CLI ì¸ìë¡œ config ìƒì„±
        config = {
            'audio': {
                'sample_rate': 8000,
                'frame_ms': 40
            },
            'watermark': {
                'payload_length': args.message_dim
            },
            'model': {
                'hidden_channels': [32, 64, 128, 256],
                'num_residual_blocks': 4
            },
            'training': {
                'epochs': args.epochs,
                'batch_size': args.batch_size,
                'learning_rate': args.lr,
                'adam_betas': [0.5, 0.9],
                'grad_clip': 1.0,
                'lambda_bit': 10.0,
                'lambda_audio': 10.0,
                'lambda_adv': 0.1,
                'lambda_det': 0.5,
                'lambda_stft': 2.0,
                'use_amp': not args.no_amp  # CLI ì¸ìë¡œ ì œì–´
            },
            'codec': {
                'enabled': False,
                'types': ['g711_alaw', 'g729', 'none']
            }
        }

    # CLI ì¸ìë¡œ ì˜¤ë²„ë¼ì´ë“œ (ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš°ì—ë§Œ!)
    # ì¤‘ìš”: ê¸°ë³¸ê°’(default)ì€ config íŒŒì¼ì„ ë®ì–´ì“°ì§€ ì•ŠìŒ
    if '--epochs' in sys.argv or '-epochs' in sys.argv:
        config['training']['epochs'] = args.epochs
    if '--batch_size' in sys.argv or '-batch_size' in sys.argv:
        config['training']['batch_size'] = args.batch_size
    if '--lr' in sys.argv or '-lr' in sys.argv:
        config['training']['learning_rate'] = args.lr
    if args.no_amp:  # flag ì¸ìëŠ” ì¡´ì¬ ì—¬ë¶€ë¡œ íŒë‹¨
        config['training']['use_amp'] = False

    # ========================================
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    # ========================================
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)

    print(f"Using device: {device}")

    if device.type == 'cuda':
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        print(f"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        print(f"  Mixed Precision: {'Enabled' if config['training']['use_amp'] else 'Disabled'}")

    # ========================================
    # ìë™ Resume í™•ì¸
    # ========================================
    resume_path = args.resume
    if resume_path is None:
        latest_ckpt = Path("checkpoints/latest.pth")
        if latest_ckpt.exists():
            print(f"Found latest checkpoint: {latest_ckpt}")
            resume_path = str(latest_ckpt)

    # ========================================
    # ëœë¤ ì‹œë“œ
    # ========================================
    torch.manual_seed(args.seed)
    if device.type == 'cuda':
        torch.cuda.manual_seed(args.seed)

    # ========================================
    # DataLoader ìƒì„±
    # ========================================
    print(f"\nLoading data...")

    train_loader, val_loader = create_train_val_loaders(
        train_dir=args.train_dir,
        val_dir=args.val_dir,
        batch_size=config['training']['batch_size'],
        num_workers=args.num_workers,
        sample_rate=config['audio']['sample_rate'],
        pin_memory=True  # RTX 3090 ìµœì í™”
    )

    # ========================================
    # ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    # ========================================
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = Path(args.save_dir) / timestamp

    # ========================================
    # í•™ìŠµ ì‹œì‘
    # ========================================
    train(
        train_loader=train_loader,
        val_loader=val_loader,
        config=config,
        save_dir=save_dir,
        device=device,
        resume_path=Path(resume_path) if resume_path else None
    )


if __name__ == "__main__":
    main()